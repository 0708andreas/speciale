\section{Applications}

\subsection{Quantifier elimination}
One of the first applications of parametric Gröbner bases was presented by its inventor Weispfenning \cite{Weispfenning} in the original article. It concerns the problem of computing a system of polynomial equations, whose solutions are equivalent to solutions to a set of logical expressions involving polynomial equations, con- and disjunctions, negations and existential quantifiers.

Sepcifically, we're given a formula $\exists x_{1}, \dots, x_{n} : \phi(U, x_{1}, \dots, x_{n})$ where $\phi$ is a combination using $\land$ and $\lor$ of polynomial equalities and inequalities in $k[U, X]$. If $k_{1}$ is an extension field of $k$, then that formula determines a partioning of $k_{1}^{|U|}$, namely those values of $U$ where the formula is true and those where it isn't. Our goal is to find a system of polynomial equations in $k[U]$ that is satisfied in exactly the same points.

First, we need to normalize the logical expressions, to fit a format we can work with.

\begin{definition}[Positive, primitive formula]
  A logical formula $\varphi$ is called \textit{positive and primitive} if it only involves polynomial equalities in $k[X]$, conjunctions and existential quantifiers.
\end{definition}

\begin{lemma}\label{lem:logical_positive}
  Let $\phi$ be a logical formula involving polynomial equalities, conjunctions, disjunctions, negations and existential quantifiers. Then there exists a finite set of positive, primitive formula $\varphi_{1}, \varphi_{2}, \dots, \varphi_{r}$ such that $\phi \iff (\varphi_{1} \lor \dots \lor \varphi_{r})$.
\end{lemma}
\begin{proof}
  Using standard logical rules, we can find $\phi_{1}, \dots, \phi_{r}$ containing only polynomial equalities, conjunction, negation and existential quantifiers such that \[\phi \iff \bigvee_{i=1}^{r} \phi_{r}.\] Using De Morgans law and distributivity we can assume that negations are at the lowest level of the formulas. Thus, we can see the $\phi_{i}$'s as existstential formulas containing conjunctions of polynomial equations and inequations.

  Now, to eliminate the inequalities, we use the following trick: \[f(X) \neq 0 \iff \exists\, t : f(X) \cdot t - 1 = 0.\]
\end{proof}

Thus we can solve each of the positive, primitive formulas independently, and see if any of them are satifiable.

\begin{theorem}
  Let $F \subset k[U, X]$ be a finite set of polynomials over an algebraically closed field and let $G$ be a parametric Gröbner basis of $F$. For a polynomial $f \in k[U][X]$, let $C(f) \subset k[U]$ denote the set of coefficients of non-constant terms in $f$. Then \[ \left(\exists x_{1}, \dots, x_{n} : \bigwedge_{f \in F} f(U, x_{1}, \dots, x_{n}) = 0 \right) \iff \bigwedge_{g \in G} \left( g(U, 0, \dots, 0) = 0 \lor \bigvee_{c \in C(g)} c(U) \neq 0 \right)\] in any extension field $k_{1} \supset k$.
\end{theorem}
\begin{proof}
  Let $\alpha \in k_{1}^{|U|}$. Then the question of whether $\exists x_{1}, \dots, x_{n} : \bigwedge_{f \in F} f(U, x_{1}, \dots, x_{n}) = 0$ is satisfied in $U = \alpha$ is equivalent to whether $\langle \sigma_{\alpha}(F) \rangle$ has a common zero, i.e. if $V(\langle \sigma_{\alpha}(F) \rangle) \neq \emptyset$.

  For the first implication, assume $\exists x_{1}, \dots, x_{n} : \bigwedge_{f \in F} f(U, x_{1}, \dots, x_{n}) = 0$ is satisfied at some $\alpha \in k_{1}^{|U|}$. Let $\beta \in k_{1}^{|X|}$ be a vector of $(x_{1}, \dots, x_{n})$ such that $f(\alpha, \beta) = 0$ for all $f \in F$. Then, since all $g \in G$ are also in $\langle F \rangle$, we get $g(\alpha, \beta) = 0 \; \forall g \in G$. Hence, if $g(\alpha, 0, \dots, 0) \neq 0$, then there has to be some non-constant term in $g$, which is also non-zero at $\alpha$.

  For the other implication, assume every $g \in G$ has zero constant term or some non-zero non-constant term, when viewed as a polynomial in $k[U][X]$. Assume for a contradiction that $V(\langle \sigma_{\alpha}(F) \rangle) = \emptyset$. By the weak Nullstellensatz we get that $1 \in \langle \sigma_{\alpha}(F) \rangle$. Since $G$ is a parametric Gröbner basis, there is some $g \in G$ such that $\LT(\sigma_{\alpha}(g)) \mid 1$. Thus $\sigma_{\alpha}(g)$ is a constant polynomial with non-zero constant term, contradicting the assumption.
\end{proof}


















\subsection{Parametric ideal membership}


\begin{theorem}
  Let $(Y, G)$ be a segment of a parametric Gröbner basis where $G = \{g_{1}, \dots, g_{n}\} \subset A[X]$, and let $f \in A[X]$ and assume that $\sigma_{\alpha}(\LC(g)) \neq 0$ for all $g \in G$ and $\alpha \in Y$. Then $\sigma_{\alpha}(f) \in \langle \sigma(G) \rangle$ for all $\alpha \in Y$ if and only if any pseudo-remainders $r$ of $f$ under pseudo-division modulo $G$ satisfies $\sigma_{\alpha}(r) = 0$ for all $\alpha \in Y$.
\end{theorem}
\begin{proof}
  If any pseudo-remainder of $f$ under pseudo-division modulo $G$ is zero, then
  \[cf = \sum_{i=1}^{n} f_{i} g_{i}\]
  for some $f_{i} \in A[X]$ and $c \in A$, where $c$ is a product of leading coefficients of $G$. Since none of those leading coefficients vanish under $\sigma_{\alpha}$, we have $\sigma_{\alpha}(c) \neq 0$. Hence
  \[\sigma_{\alpha}(f) = \frac 1 {\sigma_{\alpha}(c)}\sum_{i=1}^{n} \sigma_{\alpha}(f_{i} g_{i})\]
  so $\sigma_{\alpha}(f) \in \langle \sigma_{\alpha}(G) \rangle$.

  On the other hand, assume $\sigma_{\alpha}(f) \in \langle \sigma_{\alpha}(G) \rangle$ for all $\alpha \in Y$. Fix a specialization $\sigma_{\alpha}$, and note that if
  \[cf = r + \sum_{i=1}^{n} f_{i} g_{i}\]
  is a pseudo-division, then $\sigma_{\alpha}(f) \in \langle \sigma_{\alpha}(G) \rangle$ if and only if $\sigma_{\alpha}(r) = 0$. Thus $\sigma_{\alpha}(r) = 0$ for all $\alpha \in Y$, since $\sigma_{\alpha}(f) \in \langle \sigma_{\alpha}(G) \rangle$ for all $\alpha$.
\end{proof}

We can use this theorem to discover geometric theorems in the complex plane. Let us look at an example from \cite{MONTES20101391}.

\begin{example}
  Consider a triangle with vertices $A = (-1, 0)$, $B = (1, 0)$ and $C = (a, b)$. Now, draw the three altitudes of the triangle $ABC$, and label their basepoints $P_{1} = (x_{1}, y_{1})$, $P_{2} = (x_{2}, y_{2})$ and $P_{3} = (x_{3}, y_{3})$. We wish to determine when the triangle $P_{1}P_{2}P_{3}$ is isosceles with $|P_{1}P_{2}| = |P_{1}P_{3}|$.

  To solve this problem, we produce a parametric ideal that describes the setup. First, observe that $x_{1} = a$ and $y1 = 0$. Hence, we make that substitution immediately. This also ensures that $P_{1}C$ is orthogonal to $AB$. Next, we need that the line $AP_{2}$ is orthogonal to the line $BC$. This means $0 = AP_{2} \cdot BC = b(x_{2} + 1) - (a - 1)y_{2}$. Similarly, to ensure that $BP_{3}$ is orthogonal to $AC$, we have $0 = b(x_{3} - 1) - (a + 1)y_{3}$. We also need to ensure that the points $P_{2}$ and $P_{3}$ lies on the edges of the triangle. This is done by forcing $0 = b(x_{2} - a) + (1 - a)(y_{2} - b)$ and $0 = (y_{3} - b)(a + 1) - b(x3 - a)$. Hence, the following ideal describes the setup:
  \begin{align*}
    I = \langle\; &b(x_{2} + 1) - (a - 1)y_{2}, \quad  (1 - a)(y_{2} - b) + b(x_{2} - a), \\
                &b(x_{3} - 1) - (a + 1)y_{3}, \quad  (1 + a)(y_{3} - b) - b(x_{3} - a) \; \rangle
  \end{align*}

  We want to determine for which values of $a$ and $b$ we have that $\,|P_{1} P_{2}| = |P_{1} P_{3}|$, i.e.\ that $\,0 = (x_{3} - a)^{2} + y_{3}^{2} - (x_{2} - a)^{2} + y_{2}^{2}$. This is equivalent to asking whether $\sigma(f) \in \langle \sigma(I) \rangle$ for some specialization $\sigma : \C[a, b] \to \C$.




\end{example}












\subsection[Bernds conjecture]{Bernds conjecture\footnote{Named such by Bernd Sturmfels in a private communication to the supervisor of this project.}}
In the article \cite{sturmfels}, Bernd Sturmfels states the following theorem without proof.

\begin{theorem}
  Let $K$ be an algebraically closed field and $F = \{f_{1}, \dots, f_{k}\} \subset K[x_{1}, \dots, x_{n}]$ a finite set of polynomials. Assume that $\V(F) = \emptyset$ and consider the ideal $I = \langle y_{1} - f_{1}, \dots, y_{k} - f_{k} \rangle \subset K[x_{1}, \dots, x_{n}, y_{1}, \dots, y_{k}]$. Let $G$ be a Gröbner basis of $I$ with respect to the lexicographic order with $x_{1} > \dots > x_{n} > y_{1} > \dots > y_{k}$. Then $G$ contains a polynomial $p$ (called a final polynomial) such that
  \begin{enumerate}
    \item $p(x_{1}, \dots, x_{n}, 0, 0, \dots, 0) \in K \setminus \{0\}$
    \item $p(x_{1}, \dots, x_{n}, f_{1}, \dots, f_{k}) = 0$.
  \end{enumerate}
\end{theorem}

He writes that the proof is ``straightforward but fairly technical''. In a private communication\cite{NL_to_BS} with Sturmfels, he encourages us to write a proof or find a counterexample. He also writes, that the gist of the argument he had in mind was, that since $\{x_{1}, \dots, x_{n}\} \gg \{y_{1}, \dots, y_{k}\}$, the Gröbner basis of $I$ will specialize to a Gröbner basis of $\langle F \rangle$, when we specialize the $y_{i}$'s to zero. However, this does not always hold. Indeed, the following counterexample disproves the theorem.

\begin{example}\upshape
  Let $F = \{f_{1}, f_{2}\}$ where $f_{1} = x_{1} x_{2} + 1$ and $f_{2} = x_{2}$. Then, the corresponding ideal
  $I = \langle y_{1} - f_{1}, y_{2} - f_{2} \rangle$ has the following reduced Gröbner basis w.r.t. the lexicographic order with $x_{1} > x_{2} > y_{1} > y_{2}$: $G =  \{g_{1}, g_{2}\}$ where $g_{1} = x_{2} - y_{2}$ and $ g_{2} = y_{2}x_{1} - y_{1} + 1$. Consider now $G' = \{g_{1}, g_{1} - g_{2}\} = \{x_{2} - y_{2}, y_{2}x_{1} + x_{2} - y_{1} - y_{2} + 1\}$. Clearly $\langle G' \rangle = \langle G \rangle = I$, and it is still a Gröbner basis since $\LT(G') = \LT(G)$. However, letting $\sigma$ be the specialization setting $\sigma(y_{1}) = \sigma(y_{2}) = 0$, we see that
  \[\sigma(G') = \{x_{2}, 1+x_{2}\}\]
  which is not a Gröbner basis. Furthermore, we see that $G'$ does not contain a final polynomial.
\end{example}

While this example is admittedly a bit contrived, the theorem if false, even if we require the reduced Gröbner basis.

\begin{example}\upshape
    Let $F = \{f_1, f_2, f_3\}$ where $f_1 = x_2 + x_3$, $f_2 = x_2 x_3$ and $f_3 = x_1 x_3 + 1$. The reduced Gröbner basis of $\langle F \rangle$ is $\{1\}$, so $F$ has no common zeros. The graph ideal of $F$, $I = \langle y_1 - f_1, y_2 - f_2, y_3 - f_3 \rangle$ has the reduced Gröbner basis
    \begin{gather*}
    G = \{ x_1 y_2 + x_3 y_3 - x_3 - y_1 y_3 + y_1, x_3^2 - x_3 y_1 + y_2, x_2 + x_3 - y_1, x_1 x_3 - y_3 + 1\}.
    \end{gather*}
    When specializing $y_1 = y_2 = y_3 = 0$, $G$ turns into
    \[\bar G = \{ x_3^2, x_2 + x_3, -x_3, x_1 x_3 + 1\}\]
    which is not a Gröbner basis, and does not contain a constant. Hence, $G$ does not contain a final polynomial.
\end{example}


To fix the theorem, we can turn to parametric Gröbner bases. To shorten notation, let $X = \{x_{1}, \dots, x_{n}\}$ and $Y = \{y_{1}, \dots, y_{k}\}$.

\begin{theorem}
  Let $K$ be an algebraically closed field and $F = \{f_{1}, \dots, f_{k}\} \subset K[X]$ a finite set of polynomials. Assume that $\V(F) = \emptyset$ and consider the ideal $I = \langle y_{1} - f_{1}, \dots, y_{k} - f_{k} \rangle \subset K[X, Y]$. Let $G$ be a parametric Gröbner basis of $I$ with respect to the lexicographic order with $x_{1} > \dots > x_{n} > y_{1} > \dots > y_{k}$. Then $G$ contains a final polynomial.
\end{theorem}
\begin{proof}
  First, notice that every polynomial in $I$ satisfies the second property of final polynomials, since the generators does, and the evaluation map is linear. Thus, we only need to prove that a parametric Gröbner basis contains an element satisfying the first property.

  Let $G$ be a parametric Gröbner basis of $I$, and let $\sigma$ be the specialization setting $\sigma(y_{i}) = 0$ for every $i$. Since $\langle \sigma(I) \rangle = \langle F \rangle = \langle 1 \rangle$, there must be some element $g \in G$ where $\LM(G) \mid 1$, implying that $g$ is a final polynomial.
\end{proof}

However, parametric Gröbner bases can be quite expensive to compute since we need to repeatedly compute Gröbner bases, and furthermore we don't have nice bounds on the degrees. But we only care about one single specialization. This means we don't need a parametric Gröbner basis, we just need a faithful segment of a Gröbner system covering the origin. Here, we can use lemma~\ref{lem:grb_if_nmap_to_z_t}. Let $\sigma^{1} : K[t, X, Y] \to K[X, Y]$ be the map evaluating $t$ to 1, and let $\sigma^{0} : K[t, X, Y] \to K[X, Y]$ be the map evaluating $t$ to 0.

\begin{theorem}
  Let $K$ be an algebraically closed field and $F = \{f_{1}, \dots, f_{k}\} \subset K[X]$ a finite set of polynomials. Assume that $\V(F) = \emptyset$ and consider the ideal $I = \langle \hat F \rangle$ where $\hat F = \{y_{1} - f_{1}, \dots, y_{k} - f_{k}\}$. Now, let $\,G$ be the reduced Gröbner basis of the ideal $\langle t \cdot \hat F \cup (1 - t) \cdot Y \rangle \subset K[t, X, Y]$ w.r.t.\ the lexicographic order with $t > X > Y$. Then
  $\sigma^{1}(G)$ contains a final polynomial.
\end{theorem}
\begin{proof}
  Let $\sigma : K[X, Y] \to K[X]$ be the specialization setting $y_{i} = 0$ for every $i$ and let $H = \{\LC_{Y}(g) \mid g \in G, \LT(g) \notin K[X, Y], \LC_{X, Y}(g) \notin \langle Y \rangle\}$. If we have $0 \in \V(Y) \setminus \V(\lcm(H))$, then lemma~\ref{lem:grb_if_nmap_to_z_t}, gives us that $\sigma(\sigma^{1}(G))$ is a Gröbner basis of $\langle \sigma(I) \rangle = \langle F \rangle$. By the Nullstellensatz, $\langle F \rangle = \langle 1 \rangle$, so $\sigma(\sigma^{1}(G))$ has to contain a constant. This implies, that $\sigma^{1}(G)$ contains a polynomial $g$, satisfying the first condition of a final polynomial. Since $\sigma^{1}(g) \in \langle \hat F \rangle$ by lemma~\ref{lem:seperation}, it also satisfies the second condition. Indeed, every generator of $\langle \hat F \rangle$ satisfies it, and the evaluation map is linear, so every element of $\langle \hat F \rangle$ satisfies it.

  Now, we just need that $0 \in \V(Y) \setminus \V(\lcm(H))$. Note that $\V(Y) = \{0\}$, so we just need that $0 \notin \V(\lcm(H))$. By lemma~\ref{lem:LC_U_notin_S} we have that $h \notin \langle Y \rangle$ for each $h \in H$. Since $\langle Y \rangle$ is a prime ideal, this implies that $\lcm(H) \notin \langle S \rangle$. Thus $0 \notin \V(\lcm(H))$.
\end{proof}

This counterexample and theorem was developed in colaboration with Peter Lundgaard, and resulted in an article\cite{Lundgaard_Poulsen}.
