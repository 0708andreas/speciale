\section{Applications}

\subsection{Quantifier elimination}
One of the first applications of parametric Gröbner bases was presented by its inventor Weispfenning \cite{Weispfenning} in the original article. It concerns the problem of computing a system of polynomial equations, whose solutions are equivalent to solutions to a set of logical expressions involving polynomial equations, con- and disjunctions, negations and existential quantifiers.

Sepcifically, we're given a formula $\exists x_{1}, \dots, x_{n} : \phi(U, x_{1}, \dots, x_{n})$ where $\phi$ is a combination using $\land$ and $\lor$ of polynomial equalities and inequalities in $k[U, X]$. If $k_{1}$ is an extension field of $k$, then that formula determines a partioning of $k_{1}^{|U|}$, namely those values of $U$ where the formula is true and those where it isn't. Our goal is to find a system of polynomial equations in $k[U]$ that is satisfied in exactly the same points.

First, we need to normalize the logical expressions, to fit a format we can work with.

\begin{definition}[Positive, primitive formula]
  A logical formula $\varphi$ is called \textit{positive and primitive} if it only involves polynomial equalities in $k[X]$, conjunctions and existential quantifiers.
\end{definition}

\begin{lemma}\label{lem:logical_positive}
  Let $\phi$ be a logical formula involving polynomial equalities, conjunctions, disjunctions, negations and existential quantifiers. Then there exists a finite set of positive, primitive formula $\varphi_{1}, \varphi_{2}, \dots, \varphi_{r}$ such that $\phi \iff (\varphi_{1} \lor \dots \lor \varphi_{r})$.
\end{lemma}
\begin{proof}
  Using standard logical rules, we can find $\phi_{1}, \dots, \phi_{r}$ containing only polynomial equalities, conjunction, negation and existential quantifiers such that \[\phi \iff \bigvee_{i=1}^{r} \phi_{r}.\] Using De Morgans law and distributivity we can assume that negations are at the lowest level of the formulas. Thus, we can see the $\phi_{i}$'s as existstential formulas containing conjunctions of polynomial equations and inequations.

  Now, to eliminate the inequalities, we use the following trick: \[f(X) \neq 0 \iff \exists\, t : f(X) \cdot t - 1 = 0.\]
\end{proof}

Thus we can solve each of the positive, primitive formulas independently, and see if any of them are satifiable.

\begin{theorem}
  Let $F \subset k[U, X]$ be a finite set of polynomials over an algebraically closed field and let $G$ be a parametric Gröbner basis of $F$. For a polynomial $f \in k[U][X]$, let $C(f) \subset k[U]$ denote the set of coefficients of non-constant terms in $f$. Then \[ \left(\exists x_{1}, \dots, x_{n} : \bigwedge_{f \in F} f(U, x_{1}, \dots, x_{n}) = 0 \right) \iff \bigwedge_{g \in G} \left( g(U, 0, \dots, 0) = 0 \lor \bigvee_{c \in C(g)} c(U) \neq 0 \right)\] in any extension field $k_{1} \supset k$.
\end{theorem}
\begin{proof}
  Let $\alpha \in k_{1}^{|U|}$. Then the question of whether $\exists x_{1}, \dots, x_{n} : \bigwedge_{f \in F} f(U, x_{1}, \dots, x_{n}) = 0$ is satisfied in $U = \alpha$ is equivalent to whether $\langle \sigma_{\alpha}(F) \rangle$ has a common zero, i.e. if $V(\langle \sigma_{\alpha}(F) \rangle) \neq \emptyset$.

  For the first implication, assume $\exists x_{1}, \dots, x_{n} : \bigwedge_{f \in F} f(U, x_{1}, \dots, x_{n}) = 0$ is satisfied at some $\alpha \in k_{1}^{|U|}$. Let $\beta \in k_{1}^{|X|}$ be a vector of $(x_{1}, \dots, x_{n})$ such that $f(\alpha, \beta) = 0$ for all $f \in F$. Then, since all $g \in G$ are also in $\langle F \rangle$, we get $g(\alpha, \beta) = 0 \; \forall g \in G$. Hence, if $g(\alpha, 0, \dots, 0) \neq 0$, then there has to be some non-constant term in $g$, which is also non-zero at $\alpha$.

  For the other implication, assume every $g \in G$ has zero constant term or some non-zero non-constant term, when viewed as a polynomial in $k[U][X]$. Assume for a contradiction that $V(\langle \sigma_{\alpha}(F) \rangle) = \emptyset$. By the weak Nullstellensatz we get that $1 \in \langle \sigma_{\alpha}(F) \rangle$. Since $G$ is a parametric Gröbner basis, there is some $g \in G$ such that $\LT(\sigma_{\alpha}(g)) \mid 1$. Thus $\sigma_{\alpha}(g)$ is a constant polynomial with non-zero constant term, contradicting the assumption.
\end{proof}


















\subsection{Parametric ideal membership}


\begin{theorem}
  Let $(Y, G)$ be a segment of a parametric Gröbner basis where $G = \{g_{1}, \dots, g_{n}\} \subset A[X]$, and let $f \in A[X]$ and assume that $\sigma_{\alpha}(\LC(g)) \neq 0$ for all $g \in G$ and $\alpha \in Y$. Then $\sigma_{\alpha}(f) \in \langle \sigma(G) \rangle$ for all $\alpha \in Y$ if and only if any pseudo-remainders $r$ of $f$ under pseudo-division modulo $G$ satisfies $\sigma_{\alpha}(r) = 0$ for all $\alpha \in Y$.
\end{theorem}
\begin{proof}
  If any pseudo-remainder of $f$ under pseudo-division modulo $G$ is zero, then
  \[cf = \sum_{i=1}^{n} f_{i} g_{i}\]
  for some $f_{i} \in A[X]$ and $c \in A$, where $c$ is a product of leading coefficients of $G$. Since none of those leading coefficients vanish under $\sigma_{\alpha}$, we have $\sigma_{\alpha}(c) \neq 0$. Hence
  \[\sigma_{\alpha}(f) = \frac 1 {\sigma_{\alpha}(c)}\sum_{i=1}^{n} \sigma_{\alpha}(f_{i} g_{i})\]
  so $\sigma_{\alpha}(f) \in \langle \sigma_{\alpha}(G) \rangle$.

  On the other hand, assume $\sigma_{\alpha}(f) \in \langle \sigma_{\alpha}(G) \rangle$ for all $\alpha \in Y$. Fix a specialization $\sigma_{\alpha}$, and note that if
  \[cf = r + \sum_{i=1}^{n} f_{i} g_{i}\]
  is a pseudo-division, then $\sigma_{\alpha}(f) \in \langle \sigma_{\alpha}(G) \rangle$ if and only if $\sigma_{\alpha}(r) = 0$. Thus $\sigma_{\alpha}(r) = 0$ for all $\alpha \in Y$, since $\sigma_{\alpha}(f) \in \langle \sigma_{\alpha}(G) \rangle$ for all $\alpha$.
\end{proof}











\subsection[Bernds conjecture]{Bernds conjecture\footnote{Named such by Bernd Sturmfels in a private communication to the supervisor of this project.}}
In the article \cite{sturmfels}, Bernd Sturmfels states the following theorem without proof.

\begin{theorem}
  Let $K$ be an algebraically closed field and $F = \{f_{1}, \dots, f_{k}\} \subset K[x_{1}, \dots, x_{n}]$ a finite set of polynomials. Assume that $\V(F) = \emptyset$ and consider the ideal $I = \langle y_{1} - f_{1}, \dots, y_{k} - f_{k} \rangle \subset K[x_{1}, \dots, x_{n}, y_{1}, \dots, y_{k}]$. Let $G$ be a Gröbner basis of $I$ with respect to the lexicographic order with $x_{1} > \dots > x_{n} > y_{1} > \dots > y_{k}$. Then $G$ contains a polynomial $p$ (called a final polynomial) such that
  \begin{enumerate}
    \item $p(x_{1}, \dots, x_{n}, 0, 0, \dots, 0) \in K \setminus \{0\}$
    \item $p(x_{1}, \dots, x_{n}, f_{1}, \dots, f_{k}) = 0$.
  \end{enumerate}
\end{theorem}

He writes that the proof is ``straightforward but fairly technical''. In communications with Sturmfels, the gist of the argument he had in mind seems to have been, that since $\{x_{1}, \dots, x_{n}\} \gg \{y_{1}, \dots, y_{k}\}$, the Gröbner basis of $I$ will specialize to a Gröbner basis of $\langle F \rangle$, when we specialize the $y_{i}$'s to zero. However, this does not always hold. Indeed, the following counterexample disproves the theorem.

\begin{example}\upshape
  Let $F = \{f_{1}, f_{2}\}$ where $f_{1} = x_{1} x_{2} + 1$ and $f_{2} = x_{2}$. Then, the corresponding ideal
  $I = \langle y_{1} - f_{1}, y_{2} - f_{2} \rangle$ has the following reduced Gröbner basis w.r.t. the lexicographic order with $x_{1} > x_{2} > y_{1} > y_{2}$: $G =  \{g_{1}, g_{2}\}$ where $g_{1} = x_{2} - y_{2}$ and $ g_{2} = y_{2}x_{1} - y_{1} + 1$. Consider now $G' = \{g_{1}, g_{1} - g_{2}\} = \{x_{2} - y_{2}, y_{2}x_{1} + x_{2} - y_{1} - y_{2} + 1\}$. Clearly $\langle G' \rangle = \langle G \rangle = I$, and it is still a Gröbner basis since $\LT(G') = \LT(G)$. However, letting $\sigma$ be the specialization setting $\sigma(y_{1}) = \sigma(y_{2}) = 0$, we see that
  \[\sigma(G') = \{x_{2}, 1+x_{2}\}\]
  which is not a Gröbner basis. Furthermore, we see that $G'$ does not contain a final polynomial.
\end{example}

To fix the theorem, we can turn to parametric Gröbner bases. To shorten notation, let $X = \{x_{1}, \dots, x_{n}\}$ and $Y = \{y_{1}, \dots, y_{k}\}$.

\begin{theorem}
  Let $K$ be an algebraically closed field and $F = \{f_{1}, \dots, f_{k}\} \subset K[X]$ a finite set of polynomials. Assume that $\V(F) = \emptyset$ and consider the ideal $I = \langle y_{1} - f_{1}, \dots, y_{k} - f_{k} \rangle \subset K[X, Y]$. Let $G$ be a parametric Gröbner basis of $I$ with respect to the lexicographic order with $x_{1} > \dots > x_{n} > y_{1} > \dots > y_{k}$. Then $G$ contains a final polynomial.
\end{theorem}
\begin{proof}
  First, notice that every polynomial in $I$ satisfies the second property of final polynomials, since the generators does, and the evaluation map is linear. Thus, we only need to prove that a parametric Gröbner basis contains an element satisfying the first property.

  Let $G$ be a parametric Gröbner basis of $I$, and let $\sigma$ be the specialization setting $\sigma(y_{i}) = 0$ for every $i$. Since $\langle \sigma(I) \rangle = \langle F \rangle = \langle 1 \rangle$, there must be some element $g \in G$ where $\LM(G) \mid 1$, implying that $g$ is a final polynomial.
\end{proof}

However, parametric Gröbner bases can be quite expensive to compute since we need to repeatedly compute Gröbner bases, and furthermore we don't have nice bounds on the degrees. But we only care about one single specialization. This means we don't need a parametric Gröbner basis, we just need a faithful segment of a Gröbner system covering the origin. Here, we can take inspiration from lemma~\ref{lem:grb_if_nmap_to_z_t}. Let $\sigma^{1} : K[t, X, Y] \to K[X, Y]$ be the map evaluating $t$ to 1, and let $\sigma^{0} : K[t, X, Y] \to K[X, Y]$ be the map evaluating $t$ to 0. First, we need a simple fact about Gröbner bases.

\begin{lemma}\label{lem:redundant}
  Let $G$ be a Gröbner basis and assume that $g, g' \in G$ satisfies $\LT(g) \mid \LT(g')$. Then $G' = G \setminus \{g'\}$ satisfies that $\langle G' \rangle = \langle G \rangle$ and $G'$ is also a Gröbner basis.
\end{lemma}
\begin{proof}
  Find an $m$ such that $\LT(g') = m\LT(g)$ and let $f = g' - mg$. Then $f \in \langle G \rangle$ with $\LM(f) < \LM(g')$, hence $f$ reduces to 0 mod $G$, and $g'$ cannot be a part of this reduction. This means $g'$ reduces to zero mod $G'$, so $g'$ is redundant.
\end{proof}

Now, we are ready to prove the theorem:

\begin{theorem}
  Let $K$ be an algebraically closed field and $F = \{f_{1}, \dots, f_{k}\} \subset K[X]$ a finite set of polynomials. Assume that $\V(F) = \emptyset$ and consider the ideal $I = \langle \hat F \rangle$ where $\hat F = \{y_{1} - f_{1}, \dots, y_{k} - f_{k}\}$. Now, let $\,G$ be the reduced Gröbner basis of the ideal $\langle t \cdot \hat F \cup (1 - t) \cdot Y \rangle \subset K[t, X, Y]$ w.r.t.\ the lexicographic order with $t > X > Y$. Then
  % \[G' = \{\sigma^{1}(g) \mid g \in G, \LT(g) \notin K[X, Y] \}\]
  $\sigma^{1}(G)$ contains a final polynomial.
\end{theorem}
\begin{proof}
  First note, since $t$ dominates the other variables, $\LT(g) \notin K[X, Y]$ implies that $g \in k[t, X, Y] \setminus K[X, Y]$. Also, any polynomial in $G$ has degree at most 1 in $t$, again since $t$ dominates the other variables. Thus, for any polynomial $g \in G$ we can write $g = t\cdot g^{t} + g_{t}$ where $g_{t} = \sigma^{0}(g)$ and $g^{t} = \sigma^{1}(g) - \sigma^{0}(g)$.

  Let $\sigma : K[X, Y] \to K[X]$ be the map evaluating every $y_{i}$ to 0. By lemma~\ref{lem:seperation} we have that $\langle \sigma^{1}(G) \rangle = \langle \hat F \rangle$ and thus $\langle \sigma(\sigma^{1}(G)) \rangle = \langle \sigma(\hat F) \rangle = \langle F \rangle = \langle 1 \rangle$. The last equality is from the Nullstellensatz, using that $K$ is algebraically closed. Thus, if $\sigma(\sigma^{1}(G))$ is a Gröbner basis, then it must contain a polynomial whose leading term divides $1$. This means that there is some $g \in G$ such that $\LT(\sigma(\sigma^{1}(g))) \mid 1$, meaning $\sigma^{1}(g) \in \langle \hat F \rangle$ is a final polynomial.

  To show that $\sigma(\sigma^{1}(G))$ is a Gröbner basis, let $G' = \{g \in G \mid \LT(g) \notin K[X, Y], \sigma(\LC_{Y}(g)) \neq 0\}$. First, we prove that $\langle \sigma(\sigma^{1}(G)) \rangle = \langle \sigma(\sigma^{1}(G')) \rangle$. Indeed, for any $g \in G \setminus G'$ we have two cases.
  \begin{itemize}
    \item If $\LT(g) \in K[X, Y]$, we have that $g \in K[X, Y]$ since $t$ dominates the other variables. Thus $g = \sigma^{0}(g) \in \langle Y \rangle$ by lemma~\ref{lem:seperation}, and since $\langle \sigma(Y) \rangle = \langle 0 \rangle$, we get that $\sigma(\sigma^{1}(g)) = 0$.
    \item $\LT(g) \notin K[X, Y]$ but $\sigma(\LC_{Y}(g)) = 0$, we split into two cases. If $\LC_{X, Y}(g) \in K[Y]$, then $\sigma(g^{t}) = 0$ since $X \gg Y$. Since $g = tg^{t} + \sigma^{0}(g)$, we get $\sigma(g) = t\sigma(g^{t}) + \sigma(\sigma^{0}(g)) = 0$. Otherwise, we have $\LC_{X, Y}(g) \notin K[Y]$. Since $\sigma(\LC_{Y}(g)) = 0$, we get that $\LC_{Y}(g) \in K[Y] \setminus K$. Thus there is some $y_{i}$ that divides $\LC(g)$. Since $ty_{i} \in \LM(\langle t\cdot \hat F \cup (1-t)\cdot Y \rangle)$ for each $i$, there is some $g' \in G$ such that $\LM(g') \mid ty_{i} \mid t\LC(g)$. This in turn implies that $\LM(g') \mid t\LC(g)$, so $g$ is redundant by lemma~\ref{lem:redundant}. Furthermore, since $\LC_{X, Y}(g') \in K[Y]$ which is a different case, we can remove all such redundant elements.
  \end{itemize}

  Consider for a moment $\sigma$ as a map from $K[t, X, Y]$ to $K[t, X]$. By construction, we have $\sigma(\LC_{Y}(g)) \neq 0$ for all $g \in G'$. Thus, by lemma~\ref{lem:grb_if_nmap_to_z_t} we have that $\sigma(G')$ is a Gröbner basis in $K[t, X]$. To see that this implies that $\sigma(\sigma^{1}(G')) = \sigma^{1}(\sigma(G'))$ is a Gröbner basis, we note that $\sigma(g) = t\sigma(g^{t}) + \sigma(g_{t}) = t\sigma(g^{t})$. Thus $\sigma(G') = \sigma(\{t \cdot g^{t} \mid g \in G'\})$. Since $t$ divides every polynomial, and thus term, in this set, divisibility of leading terms is independent of $t$. Thus, $\sigma(\sigma^{1}(G'))$ is a Gröbner basis, and since $\langle \sigma(\sigma^{1}(G')) \rangle = \langle \sigma(\sigma^{1}(G)) \rangle = \langle F \rangle = 1$, there must be a final polynomial in $G'$. Since $G' \subset G$, $G$ contains a final polynomial.
\end{proof}

















% \begin{lemma}\label{lem:grb_if_nmap_to_z_t}
%   Let $F \subset k[X, U]$, $S \subset k[U]$ be finite sets with $V(S) \subset V(\langle F \rangle \cap k[U])$ and let $G$ be the reduced Gröbner basis of $\langle t\cdot F \cup (1-t)\cdot S \rangle$. Let also \[H = \{\LC_{U}(g) \mid g \in G,\; \LT(g) \notin k[X, U],\; \LC_{X, U}(g) \notin k[U]\}.\] Then $\sigma_{\alpha}(\sigma^{1}(G))$ is a Gröbner basis of $\langle \sigma_{\alpha}(F) \rangle$ for any $\alpha \in V(S) \setminus V(\lcm(H))$.
% \end{lemma}
% \begin{proof}
%   First note, that $\LT(g) \notin k[X, U]$ means that the leading term of $g$ contains the variable $t$ and, since $t$ dominates the other variables, this means that $g \in k[t, X, U] \setminus k[X, U]$. Also, any polynomial in $G$ has degree at most 1 in $t$, again since $t$ dominates the other variables. For any polynomial $g \in G$ we can therefor write $g = t\,g^{t} + g_{t}$ where $g_{t} = \sigma^{0}(g)$ and $g^{t} = \sigma^{1}(g) - \sigma^{0}(g)$.

%   Let $\alpha \in V(S) \setminus V(\lcm(H))$. By lemma~\ref{lem:seperation} we have that $\langle \sigma^{1}(G) \rangle = \langle F \rangle$ and thus $\langle \sigma_{\alpha}(\sigma^{1}(G)) \rangle = \langle \sigma_{\alpha}(F) \rangle$ for any specialization $\sigma_{\alpha}$. Thus we only need to show that $\sigma_{\alpha}(\sigma^{1}(G))$ is a Gröbner basis for itself.

%   Let $G' = \{g \in G \mid \LT(g) \notin k[X, U],\; \LC_{X, U}(g) \notin k[U]\}$. Then $\sigma_{\alpha}(\LC_{U}(g)) \neq 0$ for any $g \in G'$ since $\alpha \notin V(\lcm(H))$. We will show later, that if $g \in G \setminus G'$ then $\sigma_{\alpha}(g) = 0$. Thus $\sigma_{\alpha}(G) = \sigma_{\alpha}(G') \cup \{0\}$. By lemma~\ref{lem:grb_if_nmap_to_z} this means that both $\sigma_{\alpha}(G)$ and $\sigma_{\alpha}(G')$ are Gröbner bases in $k_{1}[t, X]$.

%   Now we only need to show, that $\sigma_{\alpha}(\sigma^{1}(G'))$ is a Gröbner basis in $k_{1}[X]$. For any $g \in G'$ we have that $\sigma_{\alpha}(g) = \sigma_{\alpha}(t\cdot g^{t}) + \sigma_{\alpha}(g_{t})$. Since $g_{t} = \sigma^{0}(g) \in \langle S \rangle$ by lemma~\ref{lem:seperation} and $\alpha \in V(S)$, we have that $\sigma_{\alpha}(g_{t}) = 0$, thus $\sigma_{\alpha}(g) = \sigma_{\alpha}(t \cdot g^{t})$. This means that $\sigma_{\alpha}(G') = \sigma_{\alpha}(\{t \cdot g^{t} \mid g \in G'\})$. Since $t$ divides every polynomial, and thus term, in that ideal, divisibility of leading terms is independent of $t$. Thus $\sigma_{\alpha}(\sigma^{1}(G'))$ is a Gröbner basis.

%   To finish the proof, we need to prove the assertion that if $g \in G \setminus G'$ then $\sigma_{\alpha}(g) = 0$. If $g \in G \setminus G'$, then either $\LT(g) \in k[X, U]$ or $\LC_{X, U}(g) \in k[U]$. In the first case, since $t$ dominates the other variables, $g$ cannot contain $t$ as a variable. Thus $g = \sigma^{0}(g) \in \langle S \rangle_{k[X, U]}$ by lemma~\ref{lem:seperation}. Since $\alpha \in V(S)$, $\sigma_{\alpha}(g) = 0$. On the other hand, if $\LT(g) \notin k[X, U]$ but $\LC_{X, U}(g) \in k[U]$, we note that $g^{t} = \LC_{X, U}(g)$. Since $g^{t} = \sigma^{1}(g) - \sigma^{0}(g)$, we get from lemma~\ref{lem:seperation} that $g^{t} \in \langle F \rangle + \langle S \rangle = \langle F \cup S \rangle$. Since we also had $g^{t} \in k[U]$, we have $g^{t} \in \langle F \cup S \rangle \cap k[U]$. But by assumption $V(S) \subset V(\langle F \rangle \cap k[U])$, thus $\alpha \in V(S) \cap V(\langle F \rangle \cap k[U]) = V(\langle F \cup S \rangle \cap k[U])$. Hence, $\sigma_{\alpha}(g^{t}) = 0$. But we proved earlier that for any $g \in G$ we have $\sigma_{\alpha}(g_{t}) = 0$, so as $\sigma_{\alpha}(g) = t\cdot \sigma_{\alpha}(g^{t}) + \sigma_{\alpha}(g_{t}) = 0$, we are done.
% \end{proof}














% Here is a relatively clean proof, using the theory of parametric Gröbner bases and pseudo-division.

% \indent \begin{proof}
%   First note that the second property of a final polynomial is satisfied by every element in $I$, since the generators satisfy the property and the evaluation map is a ring homomorphism. Hence, we only need to prove that a Gröbner basis of $I$ w.r.t.\ the lexicographic order contains a polynomial satisfying the first property.

%   Let $I = \langle y_{1} - f_{1}, \dots, y_{k} - f_{k} \rangle$, and let $G = \{g_{1}, \dots, g_{t}\} \subset K[x_{1}, \dots, x_{n}, y_{1}, \dots, y_{k}]$ be a Gröbner basis of $I \subset K[x_{1}, \dots, x_{n}, y_{1}, \dots, y_{k}]$ w.r.t.\ the lexicographic order with $x_{1} > \dots > x_{n} > y_{1} > \dots > y_{k}$. Since every product of $y$'s is smaller than any product of $x$'s, $G$ can be seen as a Gröbner basis of $I \subset K[y_{1}, \dots, y_{k}][x_{1}, \dots, x_{n}]$ by lemma~\ref{lem:block_order}.

%   First, $I$ must contain a final polynomial. Indeed, let $\mathcal G$ be a parametric Gröbner basis of $I$ and let $\sigma : K[y_{1}, \dots, y_{k}] \to K$ be the specialization setting every $y_{i}$ to 0. Since $\langle \sigma(I) \rangle = \langle F \rangle$, and $\langle F \rangle = \langle 1 \rangle$ by the Nullstellensatz, there must be some $g \in \mathcal G$ such that $\LM(\sigma(g)) \mid 1$, hence $g$ is a final polynomial.

%   Now let $p \in I$ be a final polynomial, and by rescaling we can assume $\sigma(p) = 1$. Since $G$ is a Gröbner basis (of $I \subset K[y_{1}, \dots, y_{k}][x_{1}, \dots, x_{n}]$), we can apply the normal division algorithm in the ring $K[y_{1}, \dots, y_{k}][x_{1}, \dots, x_{n}]$ to write
%   \[p = \sum_{i=1}^{t} g_{i} h_{i}\]
%   where $\LM(g_{i}h_{i}) \leq \LM(p)$ and $\coef(h_{i}, m) \in \langle \coef(p, m') \mid m' \geq \LM(g_{i}m) \rangle$ for all monomials $m$. Since this is in particular a pseudo-division, we get that
%   \[1 = \sigma(p) = \sum_{i=1}^{t} \sigma(g_{i} h_{i})\]
%   and $\LM(\sigma(g_{i} h_{i})) \leq \LM(\sigma(p)) = 1$ by lemma~\ref{lem:ps_div_to_div}. Hence, every $g_{i}$ where $\sigma(h_{i}) \neq 0$ satisfies $\LM(\sigma(g_{i})) = 1$ implying $\sigma(g_{i}) \in K \setminus \{0\}$. This means $g_{i}$ is a final polynomial.
% \end{proof}


% \indent \begin{proof}
%   We will only prove the existence of a polynomial satisfying the first property, and will refer to any polynomial satisfying that property as a final polynomial. Let $I = \langle y_{1} - f_{1}, \dots, y_{k} - f_{k} \rangle \subset K[y_{1}, \dots, y_{k}][x_{1}, \dots, x_{n}]$ and let $\mathcal G$ be a parametric Gröbner basis of $I$. Let $\sigma : K[y_{1}, \dots, y_{k}] \to K$ be the specialization setting every $y_{i}$ to 0. Then $\mathcal G$ contains a final polynomial. To see this, notice that $\sigma(\mathcal G)$ is a Gröbner basis of $\langle \sigma(I) \rangle$ which, by the Nullstellensatz, is equal to $\langle 1 \rangle$. Hence there is some $g \in \mathcal G$ such that $\LM(\sigma(g)) \mid 1$, implying that $\sigma(g) \in K \setminus \{0\}$.

%   Now, we let $\mathcal G' = \{g \in \mathcal G \mid \sigma(g) \notin K\} = \{g_{1}, \dots, g_{t}\}$. Assume that $\mathcal G'$ is still a Gröbner basis for $I$ w.r.t. the lexicographic order. Since $I$ contains a final polynomial, say $p$, we can apply the division algorithm to write
%   \[p = \sum_{i=1}^{t} g_{i}h_{i}\]
%   which in particular is a pseudo-division. Since pseudo-divisions are stable under specializations by lemma~\ref{lem:ps_div_to_div}, we get that
%   \[1 = \sigma(p) = \sum_{i=1}^{t} \sigma(g_{i} h_{i})\]
%   and $\LM(\sigma(g_{i}h_{i})) \leq 1$. Hence, every $g_{i}$ where $h_{i} \neq 0$ satisfies $\sigma(g) \in K$, but that is a contradiction. Thus $\mathcal G'$ is not a Gröbner basis of $I$.

%   To drive it home, let $G$ be a Gröbner basis of $I \subset K[x_{1}, \dots, x_{n}, y_{1}, \dots, y_{k}]$ w.r.t. the lexicographic order and assume $G$ doesn't contain a final polynomial. Since any product of $y$'s is smaller than any product of $x$'s, we can see $G$ as a Gröbner basis of $I \subset K[y_{1}, \dots, y_{k}][x_{1}, \dots, x_{n}]$. Then, there is a parametric Gröbner basis $\mathcal G$ containing $G$. Let $\mathcal G' = \{g \in \mathcal G \mid \sigma(g) \notin K\}$. Then $G \subset \mathcal G'$, but $\mathcal G'$ is not a Gröbner basis by the above. Thus $G$ cannot be a Gröbner basis.
% \end{proof}















% First, we need a lemma.

% \begin{lemma}\label{lem:LT_is_uncontaminated}
%   Let $\{f_{1}, \dots, f_{k}\} \subset K[x_{1}, \dots, x_{n}]$ and let $G$ be the reduced Gröbner basis of the ideal $\langle y_{1} - f_{1}, \dots, y_{k} - f_{k} \rangle \subset K[x_{1}, \dots, x_{n}, y_{1}, \dots, y_{k}]$ w.r.t. the lexicographic order with $x_{1} > \dots > x_{n} > y_{1} > \dots > y_{k}$. Then for all $g \in G$, either $g \in K[y_{1}, \dots, y_{k}]$ or $\LT(g) \in K[x_{1}, \dots, x_{n}]$.
% \end{lemma}
% \begin{proof}
%   Note that the given generators of $I$ have the property, that if we write the terms of any generator in order (by the term order), then there is a term, only containing $y$'s, such that every term before it only contains $x$'s and every term after it only contains $y$'s. We wish to keep this invariant.

%   We use Buchbergers algorithm to compute a Gröbner basis. Assume that at the beginning of a certain step in the algorithm, the above invariant is satisfied. Suppose we want to reduce some S-polynomial
%   \[S(f_{i}, f_{j}) = \frac{\lcm(\LM(f_{i}), \LM(f_{j}))}{\LT(f_{i})} f_{i} - \frac{\lcm(\LM(f_{i}), \LM(f_{j}))}{\LT(f_{j})} f_{j}\]
%   If both of
% \end{proof}
